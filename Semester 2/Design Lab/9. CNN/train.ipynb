{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-23T11:31:23.106184Z",
     "iopub.status.busy": "2025-03-23T11:31:23.105795Z",
     "iopub.status.idle": "2025-03-23T11:31:23.113339Z",
     "shell.execute_reply": "2025-03-23T11:31:23.112534Z",
     "shell.execute_reply.started": "2025-03-23T11:31:23.106156Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "def set_seed(seed=71):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T11:31:30.775428Z",
     "iopub.status.busy": "2025-03-23T11:31:30.775135Z",
     "iopub.status.idle": "2025-03-23T11:31:31.701759Z",
     "shell.execute_reply": "2025-03-23T11:31:31.701054Z",
     "shell.execute_reply.started": "2025-03-23T11:31:30.775407Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# For training: resize, then random crop, and apply horizontal flip and normalization.\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),                    # Resize to 256 on the shorter side\n",
    "    transforms.RandomCrop(224),                # Random crop to 224x224\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    # Use ImageNet normalization if using a pretrained AlexNet\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# For validation: resize, then center crop, and apply normalization.\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load CIFAR10 dataset using torchvision.datasets\n",
    "dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transforms)\n",
    "\n",
    "# Split the dataset into 80% training and 20% validation using a fixed seed\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size],\n",
    "                                            generator=torch.Generator().manual_seed(10))\n",
    "# Update validation dataset to use test transforms\n",
    "val_dataset.dataset.transform = test_transforms\n",
    "\n",
    "# Create DataLoaders for training and validation\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "dataloaders = {'train': train_loader, 'val': val_loader}\n",
    "dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T11:31:38.874938Z",
     "iopub.status.busy": "2025-03-23T11:31:38.874451Z",
     "iopub.status.idle": "2025-03-23T11:31:39.678576Z",
     "shell.execute_reply": "2025-03-23T11:31:39.677964Z",
     "shell.execute_reply.started": "2025-03-23T11:31:38.874907Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load AlexNet model; use pretrained weights (or set pretrained=False to train from scratch)\n",
    "model = models.alexnet(pretrained=True)\n",
    "# Modify the final fully connected layer to output 10 classes (for CIFAR10)\n",
    "num_ftrs = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Linear(num_ftrs, 10)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss criterion and optimizer (using Adam)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Learning rate scheduler: Reduce learning rate on plateau\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T11:31:45.610852Z",
     "iopub.status.busy": "2025-03-23T11:31:45.610509Z",
     "iopub.status.idle": "2025-03-23T11:51:25.377864Z",
     "shell.execute_reply": "2025-03-23T11:51:25.376902Z",
     "shell.execute_reply.started": "2025-03-23T11:31:45.610792Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training ...\n",
      "Epoch 1/30\n",
      "----------\n",
      "Train Loss: 1.5629 Acc: 0.4244\n",
      "Val Loss: 1.2736 Acc: 0.5500\n",
      "Validation loss decreased, saving model ...\n",
      "\n",
      "Epoch 2/30\n",
      "----------\n",
      "Train Loss: 1.0190 Acc: 0.6454\n",
      "Val Loss: 0.9539 Acc: 0.6636\n",
      "Validation loss decreased, saving model ...\n",
      "\n",
      "Epoch 3/30\n",
      "----------\n",
      "Train Loss: 0.8283 Acc: 0.7144\n",
      "Val Loss: 0.7318 Acc: 0.7500\n",
      "Validation loss decreased, saving model ...\n",
      "\n",
      "Epoch 4/30\n",
      "----------\n",
      "Train Loss: 0.7154 Acc: 0.7551\n",
      "Val Loss: 0.7511 Acc: 0.7468\n",
      "\n",
      "Epoch 5/30\n",
      "----------\n",
      "Train Loss: 0.6316 Acc: 0.7849\n",
      "Val Loss: 0.7066 Acc: 0.7606\n",
      "Validation loss decreased, saving model ...\n",
      "\n",
      "Epoch 6/30\n",
      "----------\n",
      "Train Loss: 0.5763 Acc: 0.8031\n",
      "Val Loss: 0.6459 Acc: 0.7859\n",
      "Validation loss decreased, saving model ...\n",
      "\n",
      "Epoch 7/30\n",
      "----------\n",
      "Train Loss: 0.5397 Acc: 0.8164\n",
      "Val Loss: 0.6511 Acc: 0.7832\n",
      "\n",
      "Epoch 8/30\n",
      "----------\n",
      "Train Loss: 0.4905 Acc: 0.8319\n",
      "Val Loss: 0.6236 Acc: 0.7954\n",
      "Validation loss decreased, saving model ...\n",
      "\n",
      "Epoch 9/30\n",
      "----------\n",
      "Train Loss: 0.4737 Acc: 0.8384\n",
      "Val Loss: 0.7212 Acc: 0.7679\n",
      "\n",
      "Epoch 10/30\n",
      "----------\n",
      "Train Loss: 0.4511 Acc: 0.8484\n",
      "Val Loss: 0.6177 Acc: 0.8053\n",
      "Validation loss decreased, saving model ...\n",
      "\n",
      "Epoch 11/30\n",
      "----------\n",
      "Train Loss: 0.4138 Acc: 0.8610\n",
      "Val Loss: 0.6357 Acc: 0.7937\n",
      "\n",
      "Epoch 12/30\n",
      "----------\n",
      "Train Loss: 0.4081 Acc: 0.8649\n",
      "Val Loss: 0.6643 Acc: 0.7959\n",
      "\n",
      "Epoch 13/30\n",
      "----------\n",
      "Train Loss: 0.3818 Acc: 0.8711\n",
      "Val Loss: 0.6128 Acc: 0.8059\n",
      "Validation loss decreased, saving model ...\n",
      "\n",
      "Epoch 14/30\n",
      "----------\n",
      "Train Loss: 0.3692 Acc: 0.8765\n",
      "Val Loss: 0.6091 Acc: 0.8097\n",
      "Validation loss decreased, saving model ...\n",
      "\n",
      "Epoch 15/30\n",
      "----------\n",
      "Train Loss: 0.3405 Acc: 0.8871\n",
      "Val Loss: 0.5951 Acc: 0.8099\n",
      "Validation loss decreased, saving model ...\n",
      "\n",
      "Epoch 16/30\n",
      "----------\n",
      "Train Loss: 0.3225 Acc: 0.8920\n",
      "Val Loss: 0.6117 Acc: 0.8160\n",
      "\n",
      "Epoch 17/30\n",
      "----------\n",
      "Train Loss: 0.3202 Acc: 0.8963\n",
      "Val Loss: 0.6426 Acc: 0.8095\n",
      "\n",
      "Epoch 18/30\n",
      "----------\n",
      "Train Loss: 0.3159 Acc: 0.8969\n",
      "Val Loss: 0.6813 Acc: 0.7990\n",
      "\n",
      "Epoch 19/30\n",
      "----------\n",
      "Train Loss: 0.3105 Acc: 0.8988\n",
      "Val Loss: 0.7420 Acc: 0.7985\n",
      "\n",
      "Epoch 20/30\n",
      "----------\n",
      "Train Loss: 0.1387 Acc: 0.9537\n",
      "Val Loss: 0.6209 Acc: 0.8398\n",
      "Early stopping triggered.\n",
      "Training complete in 19m 40s\n",
      "Best Validation Loss: 0.5951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Early stopping parameters\n",
    "patience = 5  # epochs to wait without improvement\n",
    "best_loss = float('inf')\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "epochs_no_improve = 0\n",
    "num_epochs = 30  # maximum number of epochs\n",
    "\n",
    "since = time.time()\n",
    "print(\"Starting training ...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    print('-' * 10)\n",
    "    \n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()  # set model to training mode\n",
    "        else:\n",
    "            model.eval()   # set model to evaluation mode\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        # Iterate over data.\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass; track gradients only in train phase\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "        \n",
    "        print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "        \n",
    "        # Validate and update scheduler\n",
    "        if phase == 'val':\n",
    "            scheduler.step(epoch_loss)\n",
    "            if epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                epochs_no_improve = 0\n",
    "                print(\"Validation loss decreased, saving model ...\")\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "    \n",
    "    # Early stopping check\n",
    "    if epochs_no_improve == patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "    \n",
    "    print()\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print(f'Training complete in {time_elapsed//60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "print(f'Best Validation Loss: {best_loss:.4f}')\n",
    "\n",
    "# Load best model weights\n",
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T11:55:00.767439Z",
     "iopub.status.busy": "2025-03-23T11:55:00.767094Z",
     "iopub.status.idle": "2025-03-23T11:55:01.235706Z",
     "shell.execute_reply": "2025-03-23T11:55:01.234917Z",
     "shell.execute_reply.started": "2025-03-23T11:55:00.767415Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as alexnet.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the best model's weights\n",
    "torch.save(model.state_dict(), 'alexnet.pth')\n",
    "print(\"Model saved as alexnet.pth\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
