{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNPAjAQEYY29"
      },
      "source": [
        "# A - Dataset and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "o5zdy78U_OCQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWfL38Rj_PTU",
        "outputId": "20605aa0-8033-4d07-a34b-12832f0dae54"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/krishna/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /Users/krishna/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "start = time.time()\n",
        "# Download necessary resources for nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "TAunpMin_SQH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (13879, 2)\n",
            "Test shape: (100, 2)\n"
          ]
        }
      ],
      "source": [
        "# Reading the training and testing dataset\n",
        "train_df = pd.read_csv(\"data/train.csv\")\n",
        "test_df = pd.read_csv(\"data/test.csv\")\n",
        "\n",
        "# Shape of the datasets\n",
        "print(\"Train shape:\", train_df.shape)\n",
        "print(\"Test shape:\", test_df.shape)\n",
        "\n",
        "# Randomly sampling 100 rows for validation set\n",
        "val_df = train_df.sample(n=100, random_state=71)\n",
        "train_df = train_df.drop(val_df.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CABS7IyQ_c1F"
      },
      "outputs": [],
      "source": [
        "# Text Preprocessing Function\n",
        "def preprocess_text(text):\n",
        "    text = text.encode(\"ascii\", \"ignore\").decode() # Remove non-ASCII characters\n",
        "    text = re.sub(r'[^\\w\\s]', '', text) # Remove punctuations\n",
        "    text = text.lower() # Convert to lowercase\n",
        "    words = text.split() # Tokenization\n",
        "    stop_words = set(stopwords.words('english')) # Remove stopwords\n",
        "\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    # Lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "    # Reconstruct sentence\n",
        "    return \" \".join(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "U9Uitvb6_fC5"
      },
      "outputs": [],
      "source": [
        "# Applying preprocessing\n",
        "train_df[\"text\"] = train_df[\"text\"].astype(str).apply(preprocess_text)\n",
        "val_df[\"text\"] = val_df[\"text\"].astype(str).apply(preprocess_text)\n",
        "test_df[\"text\"] = test_df[\"text\"].astype(str).apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJjWyhx-_hab",
        "outputId": "638530ca-87fb-499a-a925-a3f7c4b19c4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing complete. Files saved!\n",
            "Time taken for section A:  44.0560188293457\n"
          ]
        }
      ],
      "source": [
        "# Save preprocessed datasets\n",
        "train_df.to_csv(\"train_preprocessed.csv\", index=False)\n",
        "val_df.to_csv(\"val_preprocessed.csv\", index=False)\n",
        "test_df.to_csv(\"test_preprocessed.csv\", index=False)\n",
        "\n",
        "print(\"Preprocessing complete. Files saved!\")\n",
        "\n",
        "end = time.time()\n",
        "print(\"Time taken for section A: \", end-start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqArd-ihb6R1"
      },
      "source": [
        "# B - Estimation Using Maximum Likelihood"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fee-ZNQOAyhi"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jp9ZyPORFZE8"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "\n",
        "# Load preprocessed training dataset\n",
        "train_df = pd.read_csv(\"train_preprocessed.csv\")\n",
        "train_sentences = [sentence.split() for sentence in train_df[\"text\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zdWn0DI9FcwI"
      },
      "outputs": [],
      "source": [
        "# Define minimum document frequency threshold (1% of total articles)\n",
        "num_articles = len(train_sentences)\n",
        "min_doc_freq = max(1, int(0.01 * num_articles))  # At least 1% of articles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "D4DObpFnFgKo"
      },
      "outputs": [],
      "source": [
        "# Function to count n-grams and track article frequency\n",
        "def count_ngrams(sentences, n):\n",
        "    counts = defaultdict(int)\n",
        "    doc_freq = defaultdict(int)\n",
        "\n",
        "    for _, sentence in enumerate(sentences):\n",
        "        if not sentence:  # Skip empty sentences\n",
        "            continue\n",
        "\n",
        "        # Add start and end tokens\n",
        "        tokens = [\"<s>\"] * (n - 1) + sentence + [\"</s>\"]\n",
        "        seen_ngrams = set()\n",
        "\n",
        "        for i in range(len(tokens) - n + 1):\n",
        "            ngram = tuple(tokens[i:i + n])\n",
        "            counts[ngram] += 1\n",
        "            seen_ngrams.add(ngram)\n",
        "\n",
        "        # Update document frequency count\n",
        "        for ngram in seen_ngrams:\n",
        "            doc_freq[ngram] += 1\n",
        "\n",
        "    # Filter n-grams appearing in at least 1% of articles\n",
        "    filtered_counts = {\n",
        "        ngram: count for ngram, count in counts.items() if doc_freq[ngram] >= min_doc_freq\n",
        "    }\n",
        "    total_filtered_ngrams = sum(filtered_counts.values())\n",
        "\n",
        "    return filtered_counts, total_filtered_ngrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4IAqn8F2Fimh"
      },
      "outputs": [],
      "source": [
        "# Compute unigram, bigram, and trigram counts with filtering\n",
        "unigram_counts, total_unigrams = count_ngrams(train_sentences, 1)\n",
        "bigram_counts, total_bigrams = count_ngrams(train_sentences, 2)\n",
        "trigram_counts, total_trigrams = count_ngrams(train_sentences, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9M7KcBLcFk2j"
      },
      "outputs": [],
      "source": [
        "# Function to convert counts to probabilities with Laplace smoothing\n",
        "def compute_probabilities(counts, total, vocab_size, smoothing=1):\n",
        "    probs = {}\n",
        "    for ngram, count in counts.items():\n",
        "        probs[str(ngram)] = (count + smoothing) / (total + vocab_size * smoothing)\n",
        "    return probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "mzLXYGA4FnaC"
      },
      "outputs": [],
      "source": [
        "# Compute vocabulary sizes for unigram, bigram, and trigram models\n",
        "vocab_size_unigram = len(unigram_counts)\n",
        "vocab_size_bigram = len(bigram_counts)\n",
        "vocab_size_trigram = len(trigram_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "0XP4I7FBNkh6"
      },
      "outputs": [],
      "source": [
        "# Compute probabilities with smoothing\n",
        "unigram_probs = compute_probabilities(unigram_counts, total_unigrams, vocab_size_unigram)\n",
        "bigram_probs = compute_probabilities(bigram_counts, total_bigrams, vocab_size_bigram)\n",
        "trigram_probs = compute_probabilities(trigram_counts, total_trigrams, vocab_size_trigram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QLdUD3rFpr_",
        "outputId": "78f06a32-34e6-403f-9455-eedc6dc62cf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtered n-gram probability files generated successfully!\n",
            "Time taken for section B:  52.05514216423035\n"
          ]
        }
      ],
      "source": [
        "# Save filtered n-gram probabilities to JSON files\n",
        "with open(\"unigram_probs.json\", \"w\") as f:\n",
        "    json.dump(unigram_probs, f, indent=4)\n",
        "\n",
        "with open(\"bigram_probs.json\", \"w\") as f:\n",
        "    json.dump(bigram_probs, f, indent=4)\n",
        "\n",
        "with open(\"trigram_probs.json\", \"w\") as f:\n",
        "    json.dump(trigram_probs, f, indent=4)\n",
        "\n",
        "print(\"Filtered n-gram probability files generated successfully!\")\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "print(\"Time taken for section B: \", end-start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bA1zIw4fgqvN"
      },
      "source": [
        "# C - Evaluating an n-Gram Model using Perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "eFNoraI2glH5"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrNaKI3wglrh"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "\n",
        "# Load n-gram probability models\n",
        "with open(\"unigram_probs.json\", \"r\") as f:\n",
        "    unigram_probs = json.load(f)\n",
        "\n",
        "with open(\"bigram_probs.json\", \"r\") as f:\n",
        "    bigram_probs = json.load(f)\n",
        "\n",
        "with open(\"trigram_probs.json\", \"r\") as f:\n",
        "    trigram_probs = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_EkqbqdXoKvY"
      },
      "outputs": [],
      "source": [
        "# Load test dataset\n",
        "test_df = pd.read_csv(\"test_preprocessed.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "CpcdXGeyoM97"
      },
      "outputs": [],
      "source": [
        "# Convert test text into a list of tokenized sentences\n",
        "test_sentences = [sentence.split() for sentence in test_df[\"text\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0p6-m4l8irhB"
      },
      "outputs": [],
      "source": [
        "# Compute perplexity for a sentence using n-gram probabilities\n",
        "def compute_perplexity(ngrams_probs, sentence, n):\n",
        "    if n == 1:\n",
        "        ngram_list = [(word,) for word in sentence]  # Convert to unigram format\n",
        "    else:\n",
        "        ngram_list = [tuple(sentence[i:i+n]) for i in range(len(sentence)-n+1)]\n",
        "\n",
        "    # Compute log probabilities\n",
        "    log_probs = [np.log(ngrams_probs.get(str(ngram), 1e-10)) for ngram in ngram_list]\n",
        "    log_prob_sum = np.sum(log_probs)\n",
        "\n",
        "    # Compute perplexity\n",
        "    total_ngrams = len(ngram_list)\n",
        "    perplexity = np.exp(-log_prob_sum / total_ngrams) if total_ngrams > 0 else float('inf')\n",
        "    return perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "2ABjadXGiu6p"
      },
      "outputs": [],
      "source": [
        "# Compute perplexities for each model\n",
        "unigram_perplexities = [compute_perplexity(unigram_probs, sentence, 1) for sentence in test_sentences]\n",
        "bigram_perplexities = [compute_perplexity(bigram_probs, sentence, 2) for sentence in test_sentences]\n",
        "trigram_perplexities = [compute_perplexity(trigram_probs, sentence, 3) for sentence in test_sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "O7NLChy9izYb"
      },
      "outputs": [],
      "source": [
        "# Compute overall average perplexity for each model\n",
        "avg_unigram_perplexity = np.mean(unigram_perplexities)\n",
        "avg_bigram_perplexity = np.mean(bigram_perplexities)\n",
        "avg_trigram_perplexity = np.mean(trigram_perplexities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8wROeERi1I_",
        "outputId": "36ae0297-8b55-40be-c1b3-bd67bb8a370d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Unigram Perplexity: 85023.8164\n",
            "Average Bigram Perplexity: 1643368727.4968\n",
            "Average Trigram Perplexity: 6495576203.9299\n",
            "Time taken for section C:  0.4392430782318115\n"
          ]
        }
      ],
      "source": [
        "# Print results\n",
        "print(f\"Average Unigram Perplexity: {avg_unigram_perplexity:.4f}\")\n",
        "print(f\"Average Bigram Perplexity: {avg_bigram_perplexity:.4f}\")\n",
        "print(f\"Average Trigram Perplexity: {avg_trigram_perplexity:.4f}\")\n",
        "\n",
        "end = time.time()\n",
        "print(\"Time taken for section C: \", end-start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzennzZQw-sc"
      },
      "source": [
        "# D - Interpolation Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "QrZtSezvxVj4"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "\n",
        "# Load validation dataset\n",
        "val_df = pd.read_csv(\"val_preprocessed.csv\")\n",
        "val_sentences = [sentence.split() for sentence in val_df[\"text\"]]\n",
        "\n",
        "# Load test dataset\n",
        "test_df = pd.read_csv(\"test_preprocessed.csv\")\n",
        "test_sentences = [sentence.split() for sentence in test_df[\"text\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "11CA2jfSyK8g"
      },
      "outputs": [],
      "source": [
        "# Computes probability using interpolation smoothing \n",
        "def interpolate_prob(wi, history, lambdas):\n",
        "    unigram_prob = unigram_probs.get(str((wi,)), 1e-10)  # Use default prob if missing\n",
        "    bigram_prob = bigram_probs.get(str(tuple(history[-1:] + [wi])), unigram_prob)\n",
        "    trigram_prob = trigram_probs.get(str(tuple(history[-2:] + [wi])), bigram_prob)\n",
        "\n",
        "    return lambdas[0] * unigram_prob + lambdas[1] * bigram_prob + lambdas[2] * trigram_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "gK1fRJUFyObV"
      },
      "outputs": [],
      "source": [
        "# Compute perplexity for sentences using interpolated probabilities\n",
        "def compute_interpolated_perplexity(sentences, lambdas):\n",
        "    log_prob_sum = 0\n",
        "    total_words = 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        for i in range(len(sentence)):\n",
        "            wi = sentence[i]\n",
        "            history = sentence[max(0, i - 2):i]  # Use up to last two words as history\n",
        "            prob = interpolate_prob(wi, history, lambdas)\n",
        "\n",
        "            log_prob_sum += np.log(max(prob, 1e-10))  # Prevent log(0) issues\n",
        "            total_words += 1\n",
        "\n",
        "    return np.exp(-log_prob_sum / total_words) if total_words > 0 else float('inf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-V2irEL9ySEc",
        "outputId": "07e48962-60e3-412f-9c78-ee359a921c70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimal λ values: λ1=0.80, λ2=0.10, λ3=0.10\n",
            "Validation Perplexity: 39725.1950\n"
          ]
        }
      ],
      "source": [
        "# Optimize lambda values using the validation set\n",
        "best_perplexity = float('inf')\n",
        "best_lambdas = None\n",
        "\n",
        "for lambda1 in np.arange(0.1, 0.9, 0.1):\n",
        "    for lambda2 in np.arange(0.1, 1 - lambda1, 0.1):\n",
        "        lambda3 = 1 - (lambda1 + lambda2)\n",
        "        if lambda3 <= 0:\n",
        "            continue\n",
        "        lambdas = [lambda1, lambda2, lambda3]\n",
        "        perplexity = compute_interpolated_perplexity(val_sentences, lambdas)\n",
        "\n",
        "        if perplexity < best_perplexity:\n",
        "            best_perplexity = perplexity\n",
        "            best_lambdas = lambdas\n",
        "\n",
        "print(f\"Optimal λ values: λ1={best_lambdas[0]:.2f}, λ2={best_lambdas[1]:.2f}, λ3={best_lambdas[2]:.2f}\")\n",
        "print(f\"Validation Perplexity: {best_perplexity:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0tMtwRDyVE6",
        "outputId": "ffcfbe80-bd89-4f6a-9c88-e2d90160c69e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Perplexity using Interpolation Model: 35222.4560\n",
            "Time taken for section D:  10.085712194442749\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on the test set using the best lambda values\n",
        "test_perplexity = compute_interpolated_perplexity(test_sentences, best_lambdas)\n",
        "print(f\"Test Perplexity using Interpolation Model: {test_perplexity:.4f}\")\n",
        "\n",
        "end = time.time()\n",
        "print(\"Time taken for section D: \", end-start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a3RJTZ0xizt"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp_assignment",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
